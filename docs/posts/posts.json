[
  {
    "path": "posts/RConnections/",
    "title": "RConnections",
    "description": {},
    "author": [
      {
        "name": "Carissa Evans",
        "url": {}
      }
    ],
    "date": "2025-02-04",
    "categories": [],
    "contents": "\nA Shiny App Inspired By the NY Times Connections\n\n\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2025-02-04T13:32:44-05:00",
    "input_file": {}
  },
  {
    "path": "posts/2024-12-06-tidymodel-metrics/",
    "title": "tidymodel_metric_06122024",
    "description": {},
    "author": [
      {
        "name": "Robert Pellegrino",
        "url": {}
      }
    ],
    "date": "2024-12-06",
    "categories": [],
    "contents": "\nSimple Metrics\nNumerical\n\n\n# Simulate test-retest data\nset.seed(123)\nsimulated_data <- tibble(\n  truth = rnorm(50, mean = 70, sd = 10),  # Simulated true values\n  test_1 = truth + rnorm(50, mean = 0, sd = 5)  # Test 1 ratings with noise\n)\n\n# View the first few rows\nhead(simulated_data)\n\n# A tibble: 6 × 2\n  truth test_1\n  <dbl>  <dbl>\n1  64.4   65.7\n2  67.7   67.6\n3  85.6   85.4\n4  70.7   77.5\n5  71.3   70.2\n6  87.2   94.7\n\n# Example with one metric: RMSE\nsimulated_data %>%\n  rmse(truth = truth, estimate = test_1)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rmse    standard        4.54\n\n# Example with multiple metrics: RMSE, MAE, and R-squared\nsimulated_data %>%\n  metrics(truth = truth, estimate = test_1)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rmse    standard       4.54 \n2 rsq     standard       0.802\n3 mae     standard       3.54 \n\n# Example with multiple metrics using metric_set\n\n  ## Define a metric set\n  my_metrics <- metric_set(rmse, mae, rsq)\n\nsimulated_data %>%\n  my_metrics(truth = truth, estimate = test_1)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rmse    standard       4.54 \n2 mae     standard       3.54 \n3 rsq     standard       0.802\n\nNominal\n\n\n# Simulate test-retest categorical data\nset.seed(123)\nsimulated_data <- tibble(\n  truth = factor(rep(c(\"A\", \"B\", \"C\"), length.out = 50)),  # Simulated true classes\n  test_1 = factor(sample(c(\"A\", \"B\", \"C\"), size = 50, replace = TRUE))  # Test 1 predictions\n)\n\n# View the first few rows\nhead(simulated_data)\n\n# A tibble: 6 × 2\n  truth test_1\n  <fct> <fct> \n1 A     C     \n2 B     C     \n3 C     C     \n4 A     B     \n5 B     C     \n6 C     B     \n\n# Example with one metric: Accuracy\nsimulated_data %>%\n  accuracy(truth = truth, estimate = test_1)\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  <chr>    <chr>          <dbl>\n1 accuracy multiclass      0.48\n\n# Example with multiple metrics: Accuracy, kap\nsimulated_data %>%\n  metrics(truth = truth, estimate = test_1)\n\n# A tibble: 2 × 3\n  .metric  .estimator .estimate\n  <chr>    <chr>          <dbl>\n1 accuracy multiclass     0.48 \n2 kap      multiclass     0.221\n\n# Example with multiple metrics using metric_set\n  ## Define a metric set\n  my_metrics <- metric_set(accuracy, sens, spec)\n\nsimulated_data %>%\n  my_metrics(truth = truth, estimate = test_1)\n\n# A tibble: 3 × 3\n  .metric  .estimator .estimate\n  <chr>    <chr>          <dbl>\n1 accuracy multiclass     0.48 \n2 sens     macro          0.479\n3 spec     macro          0.741\n\nWhat the hell is tidymodel?\nTidymodels Workflow for Model Building\nPrepare Data\n    Clean, transform, and preprocess raw data.\n\n↓\n\nSplit Data\n    Divide the dataset into training and testing sets.\n\n↓\n\nDefine a Recipe\n    Specify preprocessing steps for predictors and outcomes.\n\n↓\n\nSpecify a Model\n    Choose a model (e.g., linear regression, random forest, etc.) and define its specifications.\n\n↓\n\nCreate a Workflow\n    Combine the recipe and the model into a workflow.\n\n↓\n\nCross-Validate Using Resamples\n    Use resampling techniques (e.g., k-fold CV) to tune and validate the model.\n\n↓\n\nEvaluate Performance Using Metrics\n    Assess model performance with metrics like RMSE, R-squared, accuracy, etc.\n\n↓\n\nFinalize Model\n    Fit the model on the entire training dataset.\n\n↓\n\nMake Predictions on Test Set\n    Evaluate the finalized model on the test set and make predictions.\n    \nClassification Models\nBuild the Model\nSimple model (e.g., a decision tree) using parsnip\n\n\nlibrary(tidymodels)\n\n# Prepare data\ndata(iris)\niris <- iris %>% \n  mutate(Species = as.factor(Species))\n\nset.seed(123)\niris_split <- initial_split(iris, prop = 0.8, strata = Species)\niris_train <- training(iris_split)\niris_test <- testing(iris_split)\n\n# Define a simple model\ntree_spec <- decision_tree(mode = \"classification\", tree_depth = 3) %>%\n  set_engine(\"rpart\")\n\n# Fit the model\ntree_fit <- tree_spec %>%\n  fit(Species ~ ., data = iris_train)\n\n# Make predictions\niris_predictions <- predict(tree_fit, iris_test, type = \"prob\") %>%\n  bind_cols(predict(tree_fit, iris_test, type = \"class\")) %>%\n  bind_cols(iris_test %>% select(Species))\n\nhead(iris_predictions)\n\n# A tibble: 6 × 5\n  .pred_setosa .pred_versicolor .pred_virginica .pred_class Species\n         <dbl>            <dbl>           <dbl> <fct>       <fct>  \n1            1                0               0 setosa      setosa \n2            1                0               0 setosa      setosa \n3            1                0               0 setosa      setosa \n4            1                0               0 setosa      setosa \n5            1                0               0 setosa      setosa \n6            1                0               0 setosa      setosa \n\nCheck the metrics\nStart with common classification metrics:\nAccuracy: accuracy()\nROC AUC: roc_auc()\nSensitivity/Recall: sens()\nSpecificity: spec()\nF1-score: f_meas()\n\n\nhead(iris_predictions)\n\n# A tibble: 6 × 5\n  .pred_setosa .pred_versicolor .pred_virginica .pred_class Species\n         <dbl>            <dbl>           <dbl> <fct>       <fct>  \n1            1                0               0 setosa      setosa \n2            1                0               0 setosa      setosa \n3            1                0               0 setosa      setosa \n4            1                0               0 setosa      setosa \n5            1                0               0 setosa      setosa \n6            1                0               0 setosa      setosa \n\n# Classification metrics\niris_predictions %>%\n  accuracy(truth = Species, estimate = .pred_class)\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  <chr>    <chr>          <dbl>\n1 accuracy multiclass     0.933\n\niris_predictions %>%\n  roc_auc(truth = Species, .pred_setosa, .pred_versicolor, .pred_virginica)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 roc_auc hand_till      0.967\n\niris_predictions %>%\n  sens(truth = Species, estimate = .pred_class)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 sens    macro          0.933\n\niris_predictions %>%\n  spec(truth = Species, estimate = .pred_class)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 spec    macro          0.967\n\niris_predictions %>%\n  f_meas(truth = Species, estimate = .pred_class)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 f_meas  macro          0.933\n\nIntegrate Metrics into Workflows\nMetric (from yardstick) integrates into tidymodels with resamples package\ncollect_metrics() outputs a tidy tibble of performance metrics, all powered by yardstick under the hood.\n\n\n# Prepare data\ndata(iris)\niris <- iris %>% \n  mutate(Species = as.factor(Species))\n\nset.seed(123)\niris_split <- initial_split(iris, prop = 0.8, strata = Species)\niris_train <- training(iris_split)\niris_test <- testing(iris_split)\n\n# Define a simple model\ntree_spec <- decision_tree(mode = \"classification\", tree_depth = 3) %>%\n  set_engine(\"rpart\")\n\n# Define a recipe (optional step)\niris_rec <- recipe(Species ~ ., data = iris_train) %>%\n  step_normalize(all_predictors())\n\n# Setup workflow\niris_wf <- workflow() %>%\n  add_model(tree_spec) %>%\n  add_recipe(iris_rec)\n\nset.seed(123)\niris_folds <- vfold_cv(iris_train, v = 5, strata = Species)\n\n# Resample\niris_res <- iris_wf %>%\n  fit_resamples(\n    resamples = iris_folds,\n    metrics = metric_set(accuracy, roc_auc, f_meas),\n    control = control_resamples(save_pred = TRUE)\n  )\n\n# Collect metrics\niris_res %>% collect_metrics()\n\n# A tibble: 3 × 6\n  .metric  .estimator  mean     n std_err .config             \n  <chr>    <chr>      <dbl> <int>   <dbl> <chr>               \n1 accuracy multiclass 0.942     5  0.0312 Preprocessor1_Model1\n2 f_meas   macro      0.941     5  0.0317 Preprocessor1_Model1\n3 roc_auc  hand_till  0.969     5  0.0174 Preprocessor1_Model1\n\nRegressions\nBuild and Evaluate\n\n\n# For regression: using the mtcars dataset\ndata(mtcars)\nset.seed(123)\ncar_split <- initial_split(mtcars, prop = 0.8)\ncar_train <- training(car_split)\ncar_test <- testing(car_split)\n\nlm_spec <- linear_reg() %>%\n  set_engine(\"lm\")\n\nlm_fit <- lm_spec %>% \n  fit(mpg ~ wt + hp, data = car_train)\n\ncar_preds <- car_test %>%\n  mutate(.pred = predict(lm_fit, new_data = car_test)$.pred)\n\ncar_preds %>% rmse(truth = mpg, estimate = .pred)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rmse    standard        2.09\n\ncar_preds %>% rsq(truth = mpg, estimate = .pred)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rsq     standard       0.882\n\nCustom Metrics\n\n\n# Suppose we want a custom metric, like Mean Absolute Percentage Error (MAPE)\nmape_metric <- function(data, truth, estimate, na_rm = TRUE, ...) {\n  # Extract columns\n  truth <- data[[truth]]\n  estimate <- data[[estimate]]\n  \n  mean(abs((truth - estimate) / truth), na.rm = na_rm) * 100\n}\n\n\n# Now lets use it in a workflow\n  ## For regression: using the mtcars dataset\n  data(mtcars)\n  set.seed(123)\n  car_split <- initial_split(mtcars, prop = 0.8)\n  car_train <- training(car_split)\n  car_test <- testing(car_split)\n  \n  # Define a model specification\n  lm_spec <- linear_reg() %>%\n    set_engine(\"lm\")\n  \n  # Define a recipe\n  car_rec <- recipe(mpg ~ wt + hp, data = car_train) %>%\n    step_center(all_predictors()) %>%\n    step_scale(all_predictors())\n  \n  # Create a workflow\n  car_wf <- workflow() %>%\n    add_recipe(car_rec) %>%\n    add_model(lm_spec)\n  \n  # Define resamples for cross-validation\n  car_folds <- vfold_cv(car_train, v = 5)\n  \n  # Create a metric set that includes MAPE along with other metrics\n  my_metrics <- metric_set(mape, rmse, rsq)\n\n  # Fit resamples and evaluate\n  car_res <- car_wf %>%\n    fit_resamples(\n      resamples = car_folds,\n      metrics = my_metrics,\n      control = control_resamples(save_pred = TRUE)\n    )\n  \n  # Collect the metrics\n  car_res %>% collect_metrics()\n\n# A tibble: 3 × 6\n  .metric .estimator   mean     n std_err .config             \n  <chr>   <chr>       <dbl> <int>   <dbl> <chr>               \n1 mape    standard   11.5       5  2.98   Preprocessor1_Model1\n2 rmse    standard    2.75      5  0.608  Preprocessor1_Model1\n3 rsq     standard    0.880     5  0.0411 Preprocessor1_Model1\n\nSide-by-side comparisions\n\n\n# Load necessary libraries\npacman::p_load(workflowsets)\n\n# Use the mtcars dataset\ndata(mtcars)\nset.seed(123)\ncar_split <- initial_split(mtcars, prop = 0.8)\ncar_train <- training(car_split)\ncar_test <- testing(car_split)\n\n# Define model specifications\nlm_spec <- linear_reg() %>%\n  set_engine(\"lm\")\n\nrf_spec <- rand_forest(mode = \"regression\", trees = 500) %>%\n  set_engine(\"ranger\")\n\n# Define a recipe\ncar_rec <- recipe(mpg ~ wt + hp, data = car_train) %>%\n  step_center(all_predictors()) %>%\n  step_scale(all_predictors())\n\n# Define resamples for cross-validation\ncar_folds <- vfold_cv(car_train, v = 5)\n\n# Use a standard metric set for regression\nmy_metrics <- metric_set(rmse, rsq)\n\n# Create a workflow set\nworkflow_set <- workflow_set(\n  preproc = list(car_recipe = car_rec),\n  models = list(lm = lm_spec, rf = rf_spec)\n)\n\n# Fit resamples for all workflows in the workflow set\nworkflow_results <- workflow_set %>%\n  workflow_map(\n    fn = \"fit_resamples\",\n    seed = 123,\n    resamples = car_folds,\n    metrics = my_metrics,\n    control = control_resamples(save_pred = TRUE)\n  )\n\n# Rank workflows by RMSE\nranked_results <- workflow_results %>%\n  rank_results(rank_metric = \"rmse\", select_best = TRUE)\n\n# Visualize the metrics for comparison\nautoplot(workflow_results, metric = \"rmse\") +\n  ggtitle(\"Model Comparison by RMSE\")\n\n\n#### Evaluate the Best Model on the Test Set ###########\n# Select the best model based on RMSE ranking\nbest_model <- ranked_results %>%\n  filter(rank == 1) %>%\n  pull(wflow_id) %>% unique()\n\nbest_workflow <- workflow_results %>%\n  extract_workflow(best_model)\n\n# Finalize the workflow with the best hyperparameters\nfinal_workflow <- best_workflow\n\n# Evaluate on the test set\nfinal_fit <- final_workflow %>%\n  last_fit(split = car_split, metrics = my_metrics)\n\n# Collect final metrics\ncollect_metrics(final_fit)\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  <chr>   <chr>          <dbl> <chr>               \n1 rmse    standard       2.34  Preprocessor1_Model1\n2 rsq     standard       0.621 Preprocessor1_Model1\n\n\n\n\n",
    "preview": "posts/2024-12-06-tidymodel-metrics/tidymodel_metric_06122024_files/figure-html5/unnamed-chunk-8-1.png",
    "last_modified": "2024-12-10T15:32:31-05:00",
    "input_file": {}
  },
  {
    "path": "posts/2024-11-15-time-series-machine-learning-tsml-using-modeltime/",
    "title": "Time Series Machine Learning (TSML) using modeltime pakcage",
    "description": "Time Series Machine Learning (TSML) is a specialized field that focuses on analyzing and predicting data points collected over time. It leverages patterns like trends, seasonality, and temporal dependencies to make accurate forecasts and detect anomalies. TSML combines traditional statistical methods like ARIMA with modern machine learning techniques such as LSTMs and Transformers, making it highly versatile. It plays a critical role in various industries, including finance, healthcare, and energy, enabling better decision-making and process optimization through temporal data analysis.|",
    "author": [
      {
        "name": "Cailu Lin",
        "url": "https://github.com/Cailu086Lin"
      }
    ],
    "date": "2024-11-15",
    "categories": [],
    "contents": "\n\n\nhide\n\n#packages and data\nlibrary(tidyverse)\nlibrary(tidyquant)\nlibrary(timetk)\nlibrary(tidymodels)\nlibrary(modeltime)\nlibrary(workflowsets)\n\n\n# monthly_milk_consume was simulated based on the USDA report\n\nset.seed(123)  # Set seed for reproducibility\ndates <- seq.Date(from = as.Date(\"2015-09-01\"), to = as.Date(\"2024-11-01\"), by = \"month\")\n\n# Generate random milk consumption values between 4000 and 6000 for each date\nmonthly_milk_consume <- sample(3500:6000, size = length(dates), replace = TRUE)\n\n# Create data frame\ndf <- data.frame(date = dates, monthly_milk_consume = monthly_milk_consume)\n\nplot_time_series(df,date, monthly_milk_consume, .interactive = TRUE)\n\n\n\nhide\n\n#Splitting data\nsplit <- \n  df %>% \n  time_series_split(assess = \"1 year\", \n                    cumulative = TRUE)\n\ndf_train <- training(split)\ndf_test <- testing(split)\n\n\n#Time series cross validation for tuning\n\ndf_folds <- time_series_cv(df_train,\n                           initial = 77, \n                           assess = 12)\n\n\n#Preprocessing \nrec <- \n  recipe(monthly_milk_consume ~ date, data = df_train) %>% \n  step_mutate(date_num = as.numeric(date)) %>% \n  step_date(date, features = \"month\") %>% \n  step_dummy(date_month, one_hot = TRUE) %>% \n  step_normalize(all_numeric_predictors())\n\n\nrec %>% \n  prep() %>% \n  bake(new_data = NULL) %>% view()\n\n#Model (ARIMA=Auto-Regressive Integrated Moving Average)\n\nmod <- \n  arima_boost(\n    min_n = tune(),\n    learn_rate = tune(),\n    trees = tune()\n  ) %>%\n  set_engine(engine = \"auto_arima_xgboost\")\n\n#Workflow set\nwflow_mod <- \n  workflow_set(\n    preproc = list(rec = rec),\n    models = list(mod = mod)\n  ) \n\n\n#Tuning and evaluating the model on all the samples\ngrid_ctrl <-\n  control_grid(\n    save_pred = TRUE,\n    parallel_over = \"everything\",\n    save_workflow = TRUE\n  )\n\ngrid_results <-\n  wflow_mod %>%\n  workflow_map(\n    seed = 98765,\n    resamples = df_folds,\n    grid = 10,\n    control = grid_ctrl\n  )\n\n#Accuracy of the grid results\n\ngrid_results %>% \n  rank_results(select_best = TRUE, \n               rank_metric = \"rmse\") %>%\n  select(Models = wflow_id, .metric, mean)\n\n# A tibble: 2 × 3\n  Models  .metric     mean\n  <chr>   <chr>      <dbl>\n1 rec_mod rmse    770.    \n2 rec_mod rsq       0.0492\n\nhide\n\n#Finalizing the model with the best parameters\nbest_param <- \n  grid_results %>%\n  extract_workflow_set_result(\"rec_mod\") %>% \n  select_best(metric = \"rmse\")\n\n\nwflw_fit <- \n  grid_results %>% \n  extract_workflow(\"rec_mod\") %>% \n  finalize_workflow(best_param) %>% \n  fit(df_train)\n\n#Calibrate the model to the testing set\n\ncalibration_boost <- \n  wflw_fit %>%\n  modeltime_calibrate(new_data = df_test)\n\n#Accuracy of the finalized model\ncalibration_boost %>%\n  modeltime_accuracy(metric_set = metric_set(mape, smape))\n\n# A tibble: 1 × 5\n  .model_id .model_desc                              .type  mape smape\n      <int> <chr>                                    <chr> <dbl> <dbl>\n1         1 ARIMA(1,0,1) WITH NON-ZERO MEAN W/ XGBO… Test   13.1  14.2\n\nhide\n\n#Predictive intervals and visualization\n\ncalibration_boost %>%\n  modeltime_forecast(actual_data = df %>% \n                       filter(date >= last(date) - months(12)),\n                     new_data = df_test) %>%\n  plot_modeltime_forecast(.interactive = FALSE,\n                          .legend_show = FALSE,\n                          .line_size = 1.5,\n                          .color_lab = \"\",\n                          .title = \"Monthly milk consumption, mL\") +\n  geom_point(aes(color = .key)) +\n  labs(subtitle = \"Monthly Data<br><span style = 'color:darkgrey;'>Predictive Intervals<\/span><br><span style = 'color:red;'>Point Forecast Line<\/span>\") + \n  scale_x_date(breaks = c(make_date(2023,11,1), \n                          make_date(2024,5,1),\n                          make_date(2024,10,1)),\n               labels = scales::label_date(format = \"%b'%y\"),\n               expand = expansion(mult = c(.1, .1))) +\n  ggthemes::theme_wsj(\n    base_family = \"Roboto Slab\",\n    title_family = \"Roboto Slab\",\n    color = \"blue\",\n    base_size = 12) +\n  theme(legend.position = \"none\",\n        plot.background = element_rect(fill = \"lightyellow\", color = \"lightyellow\"),\n        plot.title = element_text(size = 24),\n        axis.text = element_text(size = 16),\n        plot.subtitle = ggtext::element_markdown(size = 20, face = \"bold\"))\n\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2024-12-10T15:27:47-05:00",
    "input_file": {}
  },
  {
    "path": "posts/2024-11-01-llms-with-nailer/",
    "title": "LLMs in R with NaileR",
    "description": "This article provides an overview of the NaileR R package, which uses Large Language Models (LLMs) on local machines to interpret latent variables. It also introduces the ollamar package, which lets you run LLMs locally on your own machine.",
    "author": [
      {
        "name": "Ha Nguyen",
        "url": "https://github.com/thuhari"
      }
    ],
    "date": "2024-11-01",
    "categories": [],
    "contents": "\n\nContents\nNaileR - Introduction\nInstall and load R packages\n\nollamar - Run LLMs on local machines\nInstall and use Ollama library\n\nInterpret latent variables of QDA data\nPerfume data example\nUnivariate analysis: Analysis of variance (ANOVA) on each attribute\nSensory profile: Description of a perfume by important attributes\n\nMultivarirate analysis: PCA (Principal Component Analysis) on the adjusted means data table\nNaileR - Incorporate statistical results and LLMs\n\n\nNaileR - Introduction\nNaileR is a a small R package designed for interpreting continuous or categorical latent variables, using Large Language Model (LLM) on local machines by Ollama API. You provide a data set with a latent variable you want to understand and some other explanatory variables. It provides a description of the latent variable based on the explanatory variables. It also provides a name to the latent variable. ‘NaileR’ uses convenience functions offered by the ‘FactoMineR’ package (condes(), catdes(), descfreq()) in conjunction with the ‘ollamar’ package.\n\nSébastien Lê (2024). NaileR: Interpreting Latent Variables with AI. R package version 1.2.0, https://cran.r-project.org/web/packages/NaileR. Accessed 29 Oct. 2024.\n\nInstall and load R packages\nInstall NaileR, ollamar from GitHub for the latest/development version with more features/bug fixes\n\n\nhide\n\ninstall.packages(\"remotes\")\nremotes::install_github(\"cran/NaileR\")\nremotes::install_github(\"hauselin/ollamar\")\n\n\nLoad pakages\n\n\nhide\n\nif (!require(\"pacman\")) install.packages(\"pacman\") \npacman::p_load(tidyverse, readxl, \n               FactoMineR, SensoMineR, NaileR, stringr, glue, ollamar, magrittr,\n               base64enc, crayon, glue, httr2, jsonlite, tibble)\n\n\nNaileR imports: dplyr, stringr, glue, ollamar, magrittr, SensoMineR\nOllamar imports: base64enc, crayon, glue, httr2, jsonlite, tibble\nollamar - Run LLMs on local machines\nThe Ollama R library is the easiest way to integrate R with Ollama, which lets you run language models locally on your own machine.\nThe library also makes it easy to work with data structures (e.g., conversational/chat histories) that are standard for different LLMs (such as those provided by OpenAI and Anthropic). It also lets you specify different output formats (e.g., dataframes, text/vector, lists) that best suit your need, allowing easy integration with other libraries/tools and parallelization via the httr2 library.\nTo use this R library, ensure the Ollama app is installed. Ollama can use GPUs for accelerating LLM inference. See Ollama GPU documentation for more information.\nInstall and use Ollama library\nDownload and install Ollama from https://ollama.com/\nOpen/launch the Ollama app to start the local server\nLoad ollamar in R to connect to the Ollama local server\nDownload a LLM by running pull(\"model name\")\n\n\nhide\n\n#library(ollamar)\n\ntest_connection()  # test connection to Ollama server\n# if you see \"Ollama local server not running or wrong server,\" Ollama app/server isn't running\n\n# download a model\npull(\"llama3.2\")  # download a model (equivalent bash code: ollama run llama3.2)\npull(\"llama3\") # NaileR run `llama3` by default, can change\n# list available models (models you've pulled/downloaded)\nlist_models()\n\n# generate a response/text based on a prompt; returns an httr2 response by default\nresp <- generate(\"llama3.2\", \"tell me a 5-word story\") \n# get just the text from the response object\nresp_process(resp, \"text\")\n# get the text as a tibble dataframe\nresp_process(resp, \"df\")\n\n# alternatively, specify the output type when calling the function initially\ntxt <- generate(\"llama3.2\", \"tell me a 5-word story\", output = \"text\")\ntxt\n\n\nInterpret latent variables of QDA data\nPerfume data example\n12 perfumes were rated on 12 sensory attributes by 12 trained panelists in 2 sessions.\n\n\nhide\n\n# import data\n#library(readxl)\nqda_data <- read_excel(path = \"data/perfumes_qda.xlsx\")\nqda_data\n\n\n\n\nhide\n\nqda_data <- qda_data %>%\n  as.data.frame(qda_data) %>% # convert it into a data frame (for naming rows and SensoMineR)\n  mutate (Panelist = as.factor(Panelist),\n          Product = as.factor(Product)) # set factors\nstr(qda_data)\n\n\nUnivariate analysis: Analysis of variance (ANOVA) on each attribute\n\n\nhide\n\n#library(SensoMineR)\nres_decat <- decat(qda_data,\n                  formul = \"~Product+Panelist\",\n                  firstvar = 5,\n                  graph = FALSE\n                  ) # DEscription of CATegories with ANOVA\nres_decat$adjmean\n\n\nSensory profile: Description of a perfume by important attributes\n\n\nhide\n\nres_decat$resT$`Chanel N5`\n\n\nFor the following perceptual attributes, this stimulus has been scored with rather high values compared to the average over all stimuli; attributes have been sorted from the most discriminative one to the less discriminative one: Heady, Oriental, Wrapping, Spicy.\nFor the following perceptual attributes, this stimulus has been scored with rather low values compared to the average over all stimuli; attributes have been sorted from the most discriminative one to the less discriminative one: Greedy, Fruity, Vanilla.\nMultivarirate analysis: PCA (Principal Component Analysis) on the adjusted means data table\n\n\nhide\n\nres_pca <- PCA(res_decat$adjmean, graph = FALSE)\nplot.PCA(res_pca,choix = \"ind\") # graph of individual products\nplot.PCA(res_pca,choix = \"var\") # graph of attributes\n\n\nNaileR - Incorporate statistical results and LLMs\nRequest 1: Based on the results, please describe that particular stimulus according to its specific features. Then, based on these characteristics, give the stimulus a new name.\n\n\nhide\n\n#library(NaileR)\nintro_sensoperf <- \"Twelve perfumes were measured according to sensory attributes by a trained panel. \nI will give you the results from this study. \nYou will have to identify what sets these perfumes apart.\"\nintro_sensoperf <- gsub('\\n', ' ', intro_sensoperf) |>\n  stringr::str_squish() # remove whitespace if any\n\n# default request: Based on the results, please describe that particular stimulus according to its specific features. Then, based on these characteristics, give the stimulus a new name.\nres_nail_qda_1 <- nail_qda(qda_data,\n                         formul=\"~Product+Panelist\",\n                         firstvar = 5,\n                         introduction = intro_sensoperf,\n                         request = NULL, # default request\n                         model = 'llama3.2',\n                         isolate.groups = FALSE, #give the LLM a single prompt, or one prompt per product\n                         drop.negative = FALSE, #whether to drop negative v.test values for interpretation\n                         proba = 0.05,\n                         generate = TRUE) #generate the LLM response, otherwise, only returns the prompt\ncat(res_nail_qda_1$response)\n\n\nRun this request again to check the consistency of a response from the model.\n\n\nhide\n\nres_nail_qda_1_1 <- NaileR::nail_qda(qda_data,\n                         formul=\"~Product+Panelist\",\n                         firstvar = 5,\n                         introduction = intro_sensoperf,\n                         request = NULL,\n                         model = 'llama3.2',\n                         isolate.groups = FALSE,\n                         drop.negative = FALSE,\n                         proba = 0.05,\n                         generate = TRUE)\ncat(res_nail_qda_1_1$response)\n\n\nRequest 2: Please explain what makes each perfume distinct and provide a sensory profile of each perfume.\n\n\nhide\n\nreq_sensoperf <- \"Please explain what makes each perfume distinct\nand provide a sensory profile of each perfume\"\nreq_sensoperf <- gsub('\\n', ' ', req_sensoperf) |>\n  stringr::str_squish()\n\nres_nail_qda_2 <- NaileR::nail_qda(qda_data,\n                         formul=\"~Product+Panelist\",\n                         firstvar = 5,\n                         introduction = intro_sensoperf,\n                         request = req_sensoperf,\n                         model = 'llama3.2',\n                         isolate.groups = FALSE,\n                         drop.negative = FALSE,\n                         proba = 0.05,\n                         generate = TRUE)\ncat(res_nail_qda_2$response)\n\n\nRequest 3: Please explain what make groups of perfumes distinct and provide description of each group\n\n\nhide\n\nreq_sensoperf_3 <- \"Please explain what make groups of perfumes distinct\nand provide  description of each group\"\nreq_sensoperf_3 <- gsub('\\n', ' ', req_sensoperf_3) |>\n  stringr::str_squish()\n\nres_nail_qda_3 <- NaileR::nail_qda(qda_data,\n                         formul=\"~Product+Panelist\",\n                         firstvar = 5,\n                         introduction = intro_sensoperf,\n                         request = req_sensoperf_3,\n                         model = 'llama3.2',\n                         isolate.groups = FALSE,\n                         drop.negative = FALSE,\n                         proba = 0.05,\n                         generate = TRUE)\ncat(res_nail_qda_3$response)\n\n\nOthers: nail_catdes, nail_condes, nail_descfreq, nail_sort, nail_textual\n\n\n\n",
    "preview": {},
    "last_modified": "2024-12-10T15:27:47-05:00",
    "input_file": {}
  },
  {
    "path": "posts/GWalkR/",
    "title": "GWalkR_rclub",
    "description": "GWalkR",
    "author": [
      {
        "name": "Liz Hamel",
        "url": {}
      }
    ],
    "date": "2024-09-20",
    "categories": [],
    "contents": "\nGwalkR is a Tableau-like package that allows you to visualize and compare data without the need for ggplot and long code paragraphs.\nPlus it’s free!\nIt is simple and only requires 2 lines of code. Though, you do need to process and preformat any data you would like to use. This package allows you to visualize data and export graphs.\nIf you would like further information, you can visit the GitHub page https://github.com/Kanaries/GWalkR\nFirst Install the GWalkR package and load it\n\n\n# install.packages(\"GWalkR\")\nlibrary(GWalkR)\n\n\n\n\ndata(iris)\ngwalkr(iris)\n\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2024-10-04T10:24:28-04:00",
    "input_file": {}
  },
  {
    "path": "posts/2024-09-13-llms-in-r/",
    "title": "LLMs in R",
    "description": "Using LLMs in R",
    "author": [
      {
        "name": "Joel Mainland",
        "url": {}
      }
    ],
    "date": "2024-09-15",
    "categories": [],
    "contents": "\n\nContents\nUsing LLMs in R\nIntroduction\nGitHub Copilot\nExample 1: suggest package\nExample 2: continue pattern based on names of files\nExample 3: Ask question in comments\n\nChattr package\nExample 1: Create a simple chatbot in the Viewer\n\nAPI call to process text\nCompare to a hand-corrected version\n\n\n\nUsing LLMs in R\nIntroduction\nLet’s talk about a couple methods for using LLMs in R. I’ll be using three vignettes:\n1. GitHub Copilot\n2. chattr package\n3. API call to process text\nGitHub Copilot\nGitHub Copilot is an AI pair programmer that helps you write code faster. It is powered by OpenAI’s Codex, which is a language model trained on a diverse range of text, including code. Copilot can generate whole functions, suggest completions, and even write comments for you.\nHere is a short youtube video that can help you get Copilot and chattr working:\nhttps://www.youtube.com/watch?v=t7NrkAeosog\nExample 1: suggest package\n\n\nhide\n\nif (!require(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(tidyverse, readxl)\n\n#read in data\n\nFL_K_raw <- read_excel(\"data/raw/FL_KSU.xlsx\", sheet=3) # %>% clean_names()\n\n\nThis code throws an error because the clean_names() function is not loaded. Let’s see if Copilot can suggest the package for us.\n\n\nhide\n\nif (!require(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(tidyverse, readxl, janitor)\n\n#read in data\n\nFL_K_raw <- read_excel(\"data/raw/FL_KSU.xlsx\", sheet=3) %>% clean_names()\n\n\nAdd a comma after “readxl” and Copilot will suggest the janitor package.\nExample 2: continue pattern based on names of files\n\n\nhide\n\nFL_Ma <- read_excel(\"/Users/jmainland/Mainland Lab Dropbox/Joel Mainland/AROMA methods paper/data/raw/FL_monell_A.xlsx\", sheet = 3) \nFL_Mb <- read_excel(\"/Users/jmainland/Mainland Lab Dropbox/Joel Mainland/AROMA methods paper/data/raw/FL_monell_B.xlsx\", sheet = 3) \n\n\nThis code reads in two files, but we want to read in five files. Let’s see if Copilot can help us continue the pattern\nExample 3: Ask question in comments\n\n\nhide\n\n# q: What package can make radar plots?\n# a\n\n\n# regex to match the phone number in the format (xxx) xxx-xxxx\n\n\n#perform PCA on descriptors and make a plot using tidyverse\n\n\nThis code asks questions in the comments. Let’s see if Copilot can suggest a package that can make radar plots or regex to match a pattern.\nChattr package\nThe chattr package is a package that allows you to create interactive chatbots in R. It is built on top of the shiny package and provides a simple interface to create chatbots that can interact with users.\nExample 1: Create a simple chatbot in the Viewer\n\n\nhide\n\nremotes::install_github(\"mlverse/chattr\")\n#go to https://openai.com/blog/openai-api and sign in\n#personal > View API keys > Create a new secret key\n#Sys.setenv(OPENAI_API_KEY = “sk-…”)\n\n\n\nlibrary(chattr)\n#chattr_use(\"gpt35\")\n#chattr_use(\"gpt4\")\nchattr_use(\"copilot\")\n\n#chattr_test()\n\n#chattr_app(as_job = TRUE)\n\n\nYou can run a window inside the R interface, but it doesn’t know about your code or data frames, so to me is just a worse interface than pasting into the webpage.\nOne benefit is that you can use a local model to keep data private\nAPI call to process text\n\n\nhide\n\nlibrary(tidyverse)\nlibrary(httr)\nlibrary(stringr)\n\napi_key <- Sys.getenv(\"OPENAI_API_KEY\")\n# Calls the ChatGPT API with the given prompt and returns the answer\nask_chatgpt <- function(prompt) {\n  response <- POST(\n    url = \"https://api.openai.com/v1/chat/completions\", \n    add_headers(Authorization = paste(\"Bearer\", api_key)),\n    content_type_json(),\n    encode = \"json\",\n    body = list(\n      model = \"gpt-3.5-turbo\",\n      messages = list(list(\n        role = \"user\", \n        content = prompt\n      ))\n    )\n  )\n  str_trim(content(response)$choices[[1]]$message$content)\n}\n\ncorrect_spelling <- function(text) {\n  prompt = paste(\"Correct the spelling of the following word, only returning the corrected word itself. All words refer to smells, so correct to a word that might be used to describe an odor or desribe a chemical:\", text)\n  corrected_text <- ask_chatgpt(prompt)\n  return(corrected_text)\n}\n\n#Now check on a df\ndf <- tibble(\n  words = c(\"speling\", \"korrect\", \"writting\", \"exmaple\",\"menty\")\n)\n\ndf_corrected <- df %>%\n  mutate(corrected_words = map_chr(words, correct_spelling))\n\nhead(df_corrected)\n\n# A tibble: 5 × 2\n  words    corrected_words\n  <chr>    <chr>          \n1 speling  smelling       \n2 korrect  correct        \n3 writting whiffing       \n4 exmaple  example        \n5 menty    minty          \n\nCompare to a hand-corrected version\n\n\nhide\n\nEJM_spellcheck <- data_frame(word = c(\"perfumy\", \"mustyearthy\", \"menty\", \"buteric\", \"sulpher\", \"cinnamons\", \"vanallyn\", \n                                      \"chemcal\", \"animatic\", \"butric\", \"chloine\", \"chorine\", \"searmint\", \"medicnal\", \"tanic\", \n                                      \"grren\", \"spicey\", \"carmel\", \"diasiteal\", \"carmalized\", \"aromatica\", \"antaseptic\",\n                                      \"planty\", \"greeny\", \"alchohol\", \"pwder\", \"friuty\", \"sweey\", \"greenage\", \"acidiic\", \"saopy\",\n                                      \"liqour\", \"mente\", \"anaseed\", \"chrismas\", \"seasfood\", \"strng\", \"unplesent\", \"sublte\", \"moutwash\",\n                                      \"wintogreen\", \"fruty\", \"parfume\", \"vegatable\", \"overriped\", \"citronellaish\", \"sauekruat\", \"oinion\",\n                                      \"pungant\", \"cinammon\", \"unplesant\", \"anticeptic\"),\n                             EJMfix = c(\"perfume\", \"musty earthy\", \"mint\", \"butyric\", \"sulphur\", \"cinnamon\", \"vanillin\", \n                                     \"chemical\", \"animalic\", \"butyric\", \"chlorine\", \"chlorine\", \"spearmint\", \"medicinal\", \"tannic\", \n                                     \"green\", \"spicy\", \"caramel\", \"diacetyl\", \"caramelized\", \"aromatic\", \"antiseptic\",\n                                     \"plant\", \"green\", \"alcohol\", \"powder\", \"fruity\", \"sweet\", \"green\", \"acidic\", \"soapy\",\n                                     \"liquor\", \"mint\", \"anise\", \"christmas\", \"seafood\", \"strong\", \"unpleasent\", \"subtle\", \"mouhtwash\",\n                                     \"wintergreen\", \"fruity\", \"perfume\", \"vegetable\", \"overripe\", \"citronella\", \"sauerkraut\", \"onion\",\n                                     \"pungent\", \"cinnamon\", \"unpleasant\", \"antiseptic\"))\n\n#Note that putting your API calls in loops can be a bad idea, since you are spending money on each call. That said, the API is pretty cheap.\n\n# https://platform.openai.com/usage\n\ndf_corrected2 <- EJM_spellcheck %>%\n  mutate(corrected_by_LLM = map_chr(word, correct_spelling))\n\nhead(df_corrected2)\n\n# A tibble: 6 × 3\n  word        EJMfix       corrected_by_LLM\n  <chr>       <chr>        <chr>           \n1 perfumy     perfume      perfumey        \n2 mustyearthy musty earthy musty           \n3 menty       mint         minty           \n4 buteric     butyric      butyric         \n5 sulpher     sulphur      sulfur          \n6 cinnamons   cinnamon     cinnamal        \n\n\n\n\n",
    "preview": {},
    "last_modified": "2024-10-04T10:00:12-04:00",
    "input_file": {}
  },
  {
    "path": "posts/DREAM Olfactory Mixtures 1.0/",
    "title": "DREAM Mixture ML Intro",
    "description": {},
    "author": [
      {
        "name": "Joel Mainland",
        "url": {}
      }
    ],
    "date": "2024-06-15",
    "categories": [],
    "contents": "\n\nContents\nDREAM Olfactory Mixtures Challenge\nLook at the data\nVisualize the data\nBasic machine learning\nSplit the data\nFit a linear model\nMake predictions\nCalculate metrics\nRandom Forest\nTry the random forest model on the test set\nLook at which variables are most important\n\n\n\nDREAM Olfactory Mixtures Challenge\nThe DREAM Olfactory Mixtures Challenge launched in April of 2024.\nIn this post we will take a look at the training data for this challenge and do some very basic machine learning.\nRecent advances in predictive methods and availability of perceptual data have paved the way for a growing interest in olfactory perception predictions from chemical representations of molecules. This has led to a growing consensus that for pure odors, it is possible to build models using the chemical structure of molecules to predict the perceptual values of natural language attributes of smells. However, predictions have mainly focused on pure molecules and not the real-world situation of olfactory mixtures. In order to start filling this gap, we plan to organize a second DREAM olfaction prediction challenge now focused on predicting the discriminability of olfactory mixtures. Using publicly available data from 3 different studies (Bushdid et al 2014, Snitz et al 2013, Ravia et al 2020) for more than 700 unique mixtures and almost 600 measurements of mixture pairs discriminability, participants will be tasked to predict the discriminability of 46 unpublished mixture pairs.\nYou can register for the challenge here: https://www.synapse.org/Synapse:syn53470621/wiki/626022\nLook at the data\n\n\nhide\n\n#This is generated from Preprocessing.R\nmixturesWithFeatures <- read.csv(\"data/processed/MixturesWithFeatures.csv\")\n\n# You can load from Dropbox if you are having issues loading from the workspace:\n# mixturesWithFeatures <- read.csv(\"https://www.dropbox.com/scl/fi/f75j07xedtsv3774con0k/MixturesWithFeatures.csv?rlkey=lyfw541vdb6byhpj1341etvnu&dl=1\", row.names=NULL)\n\nglimpse(mixturesWithFeatures)\n\nRows: 548\nColumns: 11\n$ dataset             <chr> \"Snitz 1\", \"Snitz 1\", \"Snitz 1\", \"Snitz …\n$ mixture_1           <int> 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 8, 8, 8, 8…\n$ mixture_2           <int> 2, 3, 4, 5, 6, 7, 38, 39, 40, 41, 2, 3, …\n$ experimental_values <dbl> 0.6041667, 0.6510417, 0.5260417, 0.50520…\n$ a                   <chr> \"6501;264;2879;7685;7731;326;7888;61138;…\n$ b                   <chr> \"240;93009;323;8148;7762;3314;460;6184;7…\n$ num_compound_a      <int> 10, 10, 10, 10, 10, 10, 1, 1, 1, 1, 1, 1…\n$ num_compound_b      <int> 10, 1, 20, 30, 40, 4, 15, 20, 30, 43, 10…\n$ diff_mixture_size   <int> 0, 9, 10, 20, 30, 6, 14, 19, 29, 42, 9, …\n$ overlap_percent     <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ angle_dist          <dbl> 0.03592652, 0.04259934, 0.01889634, 0.02…\n\nVisualize the data\n\n\nhide\n\nmixturesWithFeatures %>%\n  ggplot(aes(x = experimental_values)) +\n  geom_histogram() +\n  labs(x=\"Percentage discrimination\")\n\n\n\nHigh values on the x-axis correspond to mixture pairs that are easy to discriminate. There are a handful of mixture pairs that are very similar to each other.\n\n\nhide\n\nggpairs(mixturesWithFeatures,columns=c(4,9,10,11))\n\n\n\n\n\nhide\n\n#Discrimination vs. Difference in size\nmixturesWithFeatures %>%\n  ggplot(aes(y = diff_mixture_size, x = experimental_values)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")+\n  labs(x=\"Percentage discrimination\",y=\"Difference in size\")\n\n\n\nIn general, mixture pairs that differ in the number of components are easier to discriminate. This effect appears to be driven by the very similar pairs that are all also very similar in size.\n\n\nhide\n\n#Discrimination vs. Percentage overlap\nmixturesWithFeatures %>%\n  ggplot(aes(y = overlap_percent, x = experimental_values)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")+\n  labs(x=\"Percentage discrimination\",y=\"Percentage overlap\")\n\n\n\nIn general, pairs with low overlap in components are easy to discriminate.\nWe can see one mixture pair that has no overlap in molecules, but could only be discriminated on ~15% of trials. This is a possible metameric pair.\nSnitz et al., 2013 has a published algorithm for predicting how similar two mixtures are, and their data are in this training set. Let’s see how well that model does on all of the data.\n\n\nhide\n\n#Discrimination vs. Angle Distance\nmixturesWithFeatures %>%\n  ggplot(aes(y = angle_dist, x = experimental_values)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")+\n  labs(x=\"Percentage discrimination\",y=\"Angle Distance\")\n\n\nhide\n\nfit1 <- lm(angle_dist ~ experimental_values, data = mixturesWithFeatures)\n\nprint(paste0(\"Adj R2 = \",signif(summary(fit1)$adj.r.squared, 5)))\n\n[1] \"Adj R2 = 0.12849\"\n\nhide\n\nprint(paste0(\" P =\",signif(summary(fit1)$coef[2,4], 5)))\n\n[1] \" P =2.805e-18\"\n\nBasic machine learning\nSplit the data\n\n\nhide\n\nmixtures.clean <- mixturesWithFeatures %>% \n  #mutate(ID = row_number()) %>%\n  select(experimental_values,diff_mixture_size,overlap_percent,angle_dist)\n\n#divide into training and test sets\nset.seed(42)\n# Create a data partition: 80% for training, 20% for testing\ntrainIndex <- createDataPartition(mixtures.clean$experimental_values, p = 0.8, list = FALSE)\n\n# Create the training and testing sets\ntrain_set <- mixtures.clean[trainIndex, ]\ntest_set <- mixtures.clean[-trainIndex, ]\n\n\nFit a linear model\n\n\nhide\n\n#fit a linear model\nmodel_linear <- lm(experimental_values ~ diff_mixture_size + overlap_percent + angle_dist, data = train_set)\n\n# View the summary of the model\nsummary(model_linear)\n\n\nCall:\nlm(formula = experimental_values ~ diff_mixture_size + overlap_percent + \n    angle_dist, data = train_set)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.46122 -0.09269  0.00589  0.09136  0.35990 \n\nCoefficients:\n                    Estimate Std. Error t value Pr(>|t|)    \n(Intercept)        0.5705318  0.0178630  31.939  < 2e-16 ***\ndiff_mixture_size  0.0003972  0.0007227   0.550 0.582810    \noverlap_percent   -0.0020038  0.0002810  -7.131 4.17e-12 ***\nangle_dist         1.0574525  0.3005934   3.518 0.000481 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1349 on 437 degrees of freedom\nMultiple R-squared:  0.2558,    Adjusted R-squared:  0.2507 \nF-statistic: 50.06 on 3 and 437 DF,  p-value: < 2.2e-16\n\nMake predictions\n\n\nhide\n\ntest_set$predicted <- predict(model_linear, newdata = test_set)\n\ntest_set %>% \n  ggplot(aes(x=experimental_values,y=predicted))+\n  geom_point() +\n  geom_smooth(method = \"lm\")+\n  labs(x=\"Percentage discrimination\",y=\"Predicted\")\n\n\n\nCalculate metrics\n\n\nhide\n\n# Calculate Mean Squared Error\nmse <- mean((test_set$experimental_values - test_set$predicted)^2)\nprint(paste(\"Mean Squared Error:\", mse))\n\n[1] \"Mean Squared Error: 0.0191725597427043\"\n\nhide\n\n# Calculate R-squared on the test set\nss_total <- sum((test_set$experimental_values - mean(test_set$experimental_values))^2)\nss_residual <- sum((test_set$experimental_values - test_set$predicted)^2)\nr_squared <- 1 - (ss_residual / ss_total)\nprint(paste(\"R-squared on test set:\", r_squared))\n\n[1] \"R-squared on test set: 0.263343178822379\"\n\nRandom Forest\n\n\nhide\n\n#Build a random forest\nr = randomForest(experimental_values ~., data=train_set, importance=TRUE, do.trace=100)\n\n     |      Out-of-bag   |\nTree |      MSE  %Var(y) |\n 100 |  0.01827    75.39 |\n 200 |  0.01816    74.93 |\n 300 |  0.01798    74.20 |\n 400 |  0.01797    74.16 |\n 500 |  0.01798    74.18 |\n\nhide\n\nprint(r)\n\n\nCall:\n randomForest(formula = experimental_values ~ ., data = train_set,      importance = TRUE, do.trace = 100) \n               Type of random forest: regression\n                     Number of trees: 500\nNo. of variables tried at each split: 1\n\n          Mean of squared residuals: 0.01797761\n                    % Var explained: 25.82\n\nTree shows the number of trees at each stage of evaluation.\nMSE is the mean-squared error of the predictions for out-of-bag samples.\nPercentage of variance explained–higher is better.\nMSE decreases slightly as we increase the number of trees, but variance explained slightly decreases. The model stablilizes around 300 trees.\nNote that the final variance explained is much lower than the estimates. This is likely because we are overfitting with only three variables.\nTry the random forest model on the test set\n\n\nhide\n\n#Now try it on the test set\nmixture.predict = predict(r, test_set)\nmixture.results <- cbind(test_set,Predicted=mixture.predict)\n\nmixture.results %>%\n  ggplot(aes(y = mixture.predict, x = experimental_values)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")+\n  labs(x=\"Percentage discrimination\",y=\"Random Forest Model\")\n\n\nhide\n\nfit2 <- lm(mixture.predict ~ experimental_values, data = mixture.results)\n\nprint(paste0(\"Adj R2 = \",signif(summary(fit2)$adj.r.squared, 5)))\n\n[1] \"Adj R2 = 0.3068\"\n\nhide\n\nprint(paste0(\" P =\",signif(summary(fit2)$coef[2,4], 5)))\n\n[1] \" P =3.6527e-10\"\n\nLook at which variables are most important\n\n\nhide\n\nimportance(r)\n\n                   %IncMSE IncNodePurity\ndiff_mixture_size 13.42197      1.115440\noverlap_percent   35.78884      2.565605\nangle_dist        30.76258      3.001925\n\n%IncMSE: This column shows the percentage increase in the mean squared error (MSE) when a given variable is randomly permuted (its values are shuffled). A higher value indicates that the variable is more important for predicting the target variable because permuting it leads to a larger increase in the MSE.\nIncNodePurity: This column shows the total decrease in node impurity (measured by residual sum of squares for regression) that results from splits on this variable, averaged over all trees. A higher value indicates that the variable contributes more to reducing the impurity of nodes in the trees, thus making it a more important predictor.\n\n\nhide\n\nvarImpPlot(r)\n\n\n\nDifference in mixture size is the least important variable. The two metrics disagree on which of the other two predictors are more important\n\n\n\n",
    "preview": "posts/DREAM Olfactory Mixtures 1.0/ML-Intro_files/figure-html5/unnamed-chunk-2-1.png",
    "last_modified": "2024-06-15T12:39:32-04:00",
    "input_file": {}
  },
  {
    "path": "posts/2024-05-16-uploading-to-the-r-club-blog1/",
    "title": "Uploading to the R club Blog",
    "description": "R Club on May 17th 2024: How to upload to the blog",
    "author": [
      {
        "name": "Vince Ramirez",
        "url": {}
      }
    ],
    "date": "2024-05-17",
    "categories": [],
    "contents": "\nA note: I am still learning the distill package and how distill blogs work. The current tutorial is to demonstrate the current workflow I have, and to motivate any R clubbers that want to help to maintain this blog.\nPurpose\nTo demonstrate how you can start contributing to the R club Blog and archive past R club presentations.\nWho?\nAnyone that takes part in R club.\nGetting Started\nIf you do not already use github/git, then please familiarize yourself with the basics. There are a number of GUI desktop applications that make using github very easy. Unfortunately I will, not cover using github in depth during today’s tutorial.\nTo contribute to the repository you will need to clone the github repository for the blog, and work within the project’s directories.\nI am assuming you are using R studio. To make everything run smoothly you should make Rmarkdown documents the standard for your R club presentations.\nFirst we will need to install the distill package.\ninstall.packages(\"distill\")\nThis will install the distill package which will allow your work to be formatted in a manner that can be implemented into the blog repository.\nThe easiest way to create a new blog post is to enter the following command in the directory of the blog\ndistill::create_post() \nThis will create a new post in the /_posts/ directory of the git repository.\ni created a new post for this R club (see below):\n\nYou can then add in your Rmarkdown file, or create a new Rmarkdown file into this repository.\nWhen beginning a new Rmarkdown file that you intend to have as a blog post, you should use the distill template.\n\nBe sure to format your YAML appropriately. An example is below\n\nYou can then run your Rmarkdown as usual.\nExample\nThe following data and example is based on analysis found at https://github.com/davestroud/BeerStudyhttps://github.com/davestroud/BeerStudy\nThe authors of this data set were interested in looking at the relationship between alcohol content (alcohol by volume or ABV) and bitterness of beer (IBU).\n\n\nlibrary(dplyr)\nlibrary(readr)\nlibrary(magrittr)\nlibrary(ggplot2)\nBeers <- read_csv(\"data/Beers.csv\")\nBreweries <- read_csv(\"data/Breweries.csv\")\n\nBeers <- Beers %>%\n  rename(Brew_ID = \"Brewery_id\")\n\nBeer_data <- left_join(Beers,Breweries, by = \"Brew_ID\")\n\n\nFirst we can look at the distribution of IBU (International Bittering Units).\n\n\nBeer_data %>%\n  ggplot(aes(x = IBU)) +\n  geom_histogram()\n\n\n\nMost beers fall under 100 IBUs, although some do approach 120+. Many beers do not have IBUs listed.\nWe can also look at ABV (alcohol by volume)\n\n\nBeer_data %>%\n  ggplot(aes(x = ABV)) +\n  geom_histogram()\n\n\n\nMost beers are under 10% ABV.\nHow does ABV and IBU correlate?\n\n\nBeer_data %>%\n  ggplot(aes(x = IBU, y = ABV)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n\nBeer_data %>%\n  ggplot(aes(x = IBU, y = ABV)) +\n  geom_point() +\n  geom_smooth(method = \"loess\")\n\n\n\nWhich State has the highest median ABV?\n\n\nMedian_ABV_IBU_State <- Beer_data %>%\n  na.omit() %>%\n  group_by(State) %>% \n  summarise(`Median ABV` = median(ABV, na.rm = T),\n            `Median IBU` = median(IBU, na.rm = T)\n            )\n\n\nMedian_ABV_IBU_State %>%\n  ggplot(aes(x = reorder(State, `Median ABV`), y = `Median ABV`)) +\n  geom_bar(stat = \"identity\") +\n  theme(axis.text.x = element_text(size=rel(0.85), angle=90)) +\n  xlab(\"State\")\n\n\n\nWhich state has the highest median IBUs?\n\n\nMedian_ABV_IBU_State %>%\n  ggplot(aes(x = reorder(State,`Median IBU`),y = `Median IBU`)) +\n  geom_bar(stat = \"identity\") +\n  theme(axis.text.x = element_text(size = rel(0.85), angle = 90)) +\n  xlab(\"State\")\n\n\n\nLet’s Plot it on a Map\nHere I plot which state has the highest median ABV using.\n\n\nlibrary(usmap)\n\nMedian_ABV_IBU_State_ <- Median_ABV_IBU_State %>%\n  rename(state = \"State\")\n\nplot_usmap(data=Median_ABV_IBU_State_,values = \"Median ABV\") +\n  scale_fill_gradient2(low = \"red\",\n                       mid = \"white\",\n                       high = \"blue\",\n                       midpoint = 0.053)\n\n\n\nAfter You Finish You Should Knit The Distill Article\nThis will create an html in our _post directory, and your post will be updated in the /docs/posts/ directory.\n\n\nChecking Your Distill HTML “index.html”\n\nFinal Steps\nYou need to push to github. We will need to figure out a work flow to have individuals push to the master branch when they have finished putting together their R markdown files. More to come soon.\n\n\n\n",
    "preview": "posts/2024-05-16-uploading-to-the-r-club-blog1/Example_files/figure-html5/unnamed-chunk-2-1.png",
    "last_modified": "2024-05-17T15:30:10-04:00",
    "input_file": {}
  },
  {
    "path": "posts/R Club November 12/",
    "title": "Getting Started with ggplot2!",
    "description": "R-Club November 12 2021",
    "author": [
      {
        "name": "Vince Ramirez",
        "url": {}
      }
    ],
    "date": "2021-11-12",
    "categories": [],
    "contents": "\nIntroduction\nThe goal of today is to learn the basic structure of a ggplot2 command to create graphics. We will be working with the mtcars dataset which is already loaded into R.\nA quick view of this data can be done using the glimpse, str, or head functions. Take your pick!\n\n\nstr(mtcars)\n\n\n'data.frame':   32 obs. of  11 variables:\n $ mpg : num  21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ...\n $ cyl : num  6 6 4 6 8 6 8 4 4 6 ...\n $ disp: num  160 160 108 258 360 ...\n $ hp  : num  110 110 93 110 175 105 245 62 95 123 ...\n $ drat: num  3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ...\n $ wt  : num  2.62 2.88 2.32 3.21 3.44 ...\n $ qsec: num  16.5 17 18.6 19.4 17 ...\n $ vs  : num  0 0 1 1 0 1 0 1 1 1 ...\n $ am  : num  1 1 1 0 0 0 0 0 0 0 ...\n $ gear: num  4 4 4 3 3 3 3 4 4 4 ...\n $ carb: num  4 4 1 1 2 1 4 2 2 4 ...\n\n\n\nhead(mtcars)\n\n\n                   mpg cyl disp  hp drat    wt  qsec vs am gear carb\nMazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\nValiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1\n\n\n\nglimpse(mtcars)\n\n\nRows: 32\nColumns: 11\n$ mpg  <dbl> 21.0, 21.0, 22.8, 21.4, 18.7, 18.1, 14.3, 24.4, 22.8, 1…\n$ cyl  <dbl> 6, 6, 4, 6, 8, 6, 8, 4, 4, 6, 6, 8, 8, 8, 8, 8, 8, 4, 4…\n$ disp <dbl> 160.0, 160.0, 108.0, 258.0, 360.0, 225.0, 360.0, 146.7,…\n$ hp   <dbl> 110, 110, 93, 110, 175, 105, 245, 62, 95, 123, 123, 180…\n$ drat <dbl> 3.90, 3.90, 3.85, 3.08, 3.15, 2.76, 3.21, 3.69, 3.92, 3…\n$ wt   <dbl> 2.620, 2.875, 2.320, 3.215, 3.440, 3.460, 3.570, 3.190,…\n$ qsec <dbl> 16.46, 17.02, 18.61, 19.44, 17.02, 20.22, 15.84, 20.00,…\n$ vs   <dbl> 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1…\n$ am   <dbl> 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1…\n$ gear <dbl> 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 4, 4…\n$ carb <dbl> 4, 4, 1, 1, 2, 1, 4, 2, 2, 4, 4, 3, 3, 3, 4, 4, 4, 1, 2…\n\nPlotting Using base-R\nWe can use the base functions in R to make plots of these data. R itself has very powerful graphic capabilities, and for many this works just fine.\nA simple plot may want to look at the relationship between horsepower and miles per gallon. This is easy visualized below\n\n\nplot(hp~mpg,data = mtcars,ylab=\"horsepower\",xlab=\"miles per gallon\")\n\n\n\n\nAn alternative method is to use the package ggplot2 in order to create your visuals.\nggplot2: A primer\nggplot2 is a powerful graphics library in R which is part of the larger tidyverse. It is praised for the ability to create powerful and highly customizable visuals with relatively simple commands.\nThese commands follow a very generic structure which is defined as follows:\nggplot2(data= x, mappings=aes())+ geom_function()\nor\nggplot2(data) + geom_function(mapping=aes())\nWhere aes() is the aesthetics in your ggplot. Here we will define our X and Y variables as well as our aesthetic choices such as our coloring schemes.\nA simple ggplot is shown below.\n\n\nggplot(data=mtcars, aes(x=mpg, y=hp)) +\n  geom_point()\n\n\n\n\nWe can see that we have recreated the plot made using base-R.\nLet’s take it a step further and customize our plot. We can invoke themes\n\n\nggplot(data=mtcars, aes(x=mpg, y=hp)) +\n  geom_point() +\n  theme_bw()\n\n\n\n\nWe can change our axis-labels\n\n\nggplot(data=mtcars, aes(x=mpg, y=hp)) + geom_point() + theme_bw() + labs(x=\"Miles Per Gallon\", y=\"Horsepower\")\n\n\n\n\nWe can change our aesthetics to categorize our data based on the number of cylinders in the engine. It needs to be converted to a factor variable (categorical variable) first.\n\n\nggplot(data=mtcars, aes(x=mpg, y=hp,col=as.factor(cyl))) +\n  geom_point() +\n  theme_bw() +\n  labs(x=\"Miles Per Gallon\", y=\"Horsepower\")\n\n\n\n\nWe can adjust our legend with the labs() command as well.\n\n\nggplot(data=mtcars, aes(x=mpg, y=hp,col=as.factor(cyl))) +\n  geom_point() +\n  theme_bw() +\n  labs(col=\"Cylinders\",x=\"Miles Per Gallon\", y=\"Horsepower\")\n\n\n\n\nIf we want a different graph for each engine type we can use facets.\n\n\nggplot(data=mtcars, aes(x=mpg, y=hp)) +\n  geom_point() +\n  theme_bw() +\n  labs(x=\"Miles Per Gallon\", y=\"Horsepower\") + facet_wrap(~cyl)\n\n\n\n\nThis just scratches the surface of what ggplot is capable of. It is a simple example, but the possibilities are almost endless.\nDifferent Graphic Types\nI have displayed a simple x-y scatter plot, but the process for other plot types is very similar. Here is an example of a highly customized plot. I will use a similar set of data already loaded into R called “mpg”.\n\n\nstr(mpg)\n\n\ntibble [234 × 11] (S3: tbl_df/tbl/data.frame)\n $ manufacturer: chr [1:234] \"audi\" \"audi\" \"audi\" \"audi\" ...\n $ model       : chr [1:234] \"a4\" \"a4\" \"a4\" \"a4\" ...\n $ displ       : num [1:234] 1.8 1.8 2 2 2.8 2.8 3.1 1.8 1.8 2 ...\n $ year        : int [1:234] 1999 1999 2008 2008 1999 1999 2008 1999 1999 2008 ...\n $ cyl         : int [1:234] 4 4 4 4 6 6 6 4 4 4 ...\n $ trans       : chr [1:234] \"auto(l5)\" \"manual(m5)\" \"manual(m6)\" \"auto(av)\" ...\n $ drv         : chr [1:234] \"f\" \"f\" \"f\" \"f\" ...\n $ cty         : int [1:234] 18 21 20 21 16 18 18 18 16 20 ...\n $ hwy         : int [1:234] 29 29 31 30 26 26 27 26 25 28 ...\n $ fl          : chr [1:234] \"p\" \"p\" \"p\" \"p\" ...\n $ class       : chr [1:234] \"compact\" \"compact\" \"compact\" \"compact\" ...\n\nI will create a violin plot which shows the distribution of the data. I am interested in mile per gallon in the city and the number of cylinders in the engine.\n\n\nggplot(data=mpg, aes(x=as.factor(cyl),y=cty)) +\n  geom_violin() +\n  theme_bw() +\n  labs(x=\"Number of Cylinders in Engine\", y=\"Miles per Gallon in the City\")\n\n\n\n\nThis reveals a lot already, but we can add more. Let’s add a box and whisker to better understand the distribution.\n\n\nggplot(data=mpg, aes(x=as.factor(cyl),y=cty)) +\n  geom_violin() +\n  theme_bw() + \n  geom_boxplot(width=0.1) +\n  labs(x=\"Number of Cylinders in Engine\", y=\"Miles per Gallon in the City\")\n\n\n\n\nWe can also add the individual points to this graph. I want to jitter the points to prevent overplotting and make them semi-transparent.\n\n\nggplot(data=mpg, aes(x=as.factor(cyl),y=cty)) +\n  geom_violin() +\n  theme_bw() + \n  geom_boxplot(width=0.1) +\n  geom_jitter(alpha=0.4) +\n  labs(x=\"Number of Cylinders in Engine\", y=\"Miles per Gallon in the City\")\n\n\n\n\nNext I will adjust the width of our jittered points.\n\n\nggplot(data=mpg, aes(x=as.factor(cyl),y=cty)) +\n  geom_violin() +\n  theme_bw() + \n  geom_boxplot(width=0.1) +\n  geom_jitter(alpha=0.3, width=0.2) +\n  labs(x=\"Number of Cylinders in Engine\", y=\"Miles per Gallon in the City\")\n\n\n\n\nWrapping Up\nggplot2 allows us to create powerful and customizable graphics using relatively simple commands. The library is well documented and maintained allowing R novices and experts to quickly pick it up. We have barely scratched the surface of what ggplot2 is able to do. Additionally, user written companion libraries exist which extend the functionality of ggplot2. The possibilities are endless.\n\n\n\n",
    "preview": "posts/R Club November 12/Getting-Started-with-ggplot2_files/figure-html5/unnamed-chunk-4-1.png",
    "last_modified": "2021-11-12T11:15:59-05:00",
    "input_file": {}
  },
  {
    "path": "posts/welcome/",
    "title": "Welcome to Rclub Blog",
    "description": "Welcome to the Rclub Blog.",
    "author": [
      {
        "name": "Vince Ramirez",
        "url": {}
      }
    ],
    "date": "2021-11-06",
    "categories": [],
    "contents": "\nIntroducing the R club Blog! A space for us to share everything R!\n\n\n\n",
    "preview": {},
    "last_modified": "2021-11-07T01:27:49-04:00",
    "input_file": {}
  },
  {
    "path": "posts/Writing Function R Club October 11/",
    "title": "R Club - Writing Functions",
    "description": "R Club",
    "author": [],
    "date": "2021-11-06",
    "categories": [],
    "contents": "\nIntroduction\nWords from our sponsors\n\n“Writing good functions is a lifetime journey. Even after using R for many years I still learn new techniques and better ways of approaching old problems.” -Hadley Wickham\n\nOne of the best ways to improve your reach as a data scientist is to write functions. Functions allow you to automate common tasks in a more powerful and general way than copy-and-pasting. Writing a function has three big advantages over using copy-and-paste:\nYou can give a function an evocative name that makes your code easier to understand.\nAs requirements change, you only need to update code in one place, instead of many.\nYou eliminate the chance of making incidental mistakes when you copy and paste (i.e. updating a variable name in one place, but not in another).\nOther material\nSource Material for Functions\nhttps://r4ds.had.co.nz/functions.html ## Source Material on Purrr https://dcl-prog.stanford.edu/purrr-parallel.html ## More on Purrr https://r4ds.had.co.nz/iteration.html#the-map-functions ## Purrr Cheatsheat https://github.com/rstudio/cheatsheets/blob/master/purrr.pdf\nCode\nPackages / Functions\n\n\nknitr::opts_chunk$set(echo = TRUE)\n\n# R Version \nR.Version()$version.string #code ran on R version 4.0.5 (2021-03-31)\n\n\n[1] \"R version 4.1.0 (2021-05-18)\"\n\n# Load packages\nif (!require(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(magrittr, scales, tidyverse)\n\nget_data <- function(){\n  df <- tibble(\n  a = rnorm(10),\n  b = rnorm(10),\n  c = rnorm(10),\n  d = rnorm(10))\n  \n  return(df)\n}\n\n\n\nData Read\n\n\n# Create a table of 10 random number with a mean of zero (SD=1)\ndf <- tibble(\n  a = rnorm(10),\n  b = rnorm(10),\n  c = rnorm(10),\n  d = rnorm(10)\n)\n\ndf\n\n\n# A tibble: 10 x 4\n        a       b      c      d\n    <dbl>   <dbl>  <dbl>  <dbl>\n 1  0.973 -0.0730  0.823 -0.151\n 2  0.953 -0.282  -0.729  0.967\n 3  0.425  0.962  -0.611 -0.795\n 4  1.91   0.323  -0.194 -0.205\n 5 -0.741 -0.429  -0.370 -0.616\n 6 -0.245  0.269  -0.509 -0.110\n 7  1.42  -1.38   -0.407 -0.272\n 8  0.868  0.402  -0.148  0.156\n 9 -0.849  1.86    1.83  -1.25 \n10 -0.509  3.54    1.29  -0.378\n\nMaking a function\n\n\n# Rescale data to be between 0 and 1\ndf$a <- (df$a - min(df$a, na.rm = TRUE)) / \n  (max(df$a, na.rm = TRUE) - min(df$a, na.rm = TRUE))\ndf$b <- (df$b - min(df$b, na.rm = TRUE)) / \n  (max(df$b, na.rm = TRUE) - min(df$a, na.rm = TRUE)) #look a mistake!\ndf$c <- (df$c - min(df$c, na.rm = TRUE)) / \n  (max(df$c, na.rm = TRUE) - min(df$c, na.rm = TRUE))\ndf$d <- (df$d - min(df$d, na.rm = TRUE)) / \n  (max(df$d, na.rm = TRUE) - min(df$d, na.rm = TRUE))\n\ndf # look at column B for the mistake from paste/copy\n\n\n# A tibble: 10 x 4\n        a     b      c     d\n    <dbl> <dbl>  <dbl> <dbl>\n 1 0.660  0.369 0.607  0.495\n 2 0.653  0.310 0      1    \n 3 0.462  0.661 0.0463 0.204\n 4 1      0.481 0.209  0.471\n 5 0.0394 0.268 0.140  0.285\n 6 0.219  0.466 0.0861 0.513\n 7 0.822  0     0.126  0.440\n 8 0.622  0.503 0.227  0.633\n 9 0      0.916 1      0    \n10 0.123  1.39  0.789  0.392\n\n# Reload OG dataframe\ndf <- get_data()\n\n# Ask yourself: Am I repeating code? Am I copy-pasting stuff?\n  ## YES! What am I repeating?\n  df$a <- (df$a - min(df$a, na.rm = TRUE)) / \n  (max(df$a, na.rm = TRUE) - min(df$a, na.rm = TRUE))\n  \n  ## Reload OG dataframe\n  df <- get_data()\n\n  ## Rewrite the code using temporary variables with general names\n  x <- df$a\n  (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))\n\n\n [1] 0.3798973 0.6395313 0.3916441 0.6788337 0.0000000 0.4547929\n [7] 1.0000000 0.8133605 0.5359254 0.3890551\n\n# Ask yourself: Is there still duplication?\n  ## YES! What am I repeating? [in this case, it's the range]\n  rng <- range(x, na.rm = TRUE)\n  (x - rng[1]) / (rng[2] - rng[1])\n\n\n [1] 0.3798973 0.6395313 0.3916441 0.6788337 0.0000000 0.4547929\n [7] 1.0000000 0.8133605 0.5359254 0.3890551\n\n# Make the function\n  rescale01 <- function(x) {\n  rng <- range(x, na.rm = TRUE)\n  (x - rng[1]) / (rng[2] - rng[1])\n  }\n  \n  ## Check to make sure it works as expected\n  rescale01(c(0, 5, 10))\n\n\n[1] 0.0 0.5 1.0\n\n  ## Add to other customized functions and apply to dataframe\n  df$a <- rescale01(df$a)\n  df$b <- rescale01(df$b)\n  df$c <- rescale01(df$c)\n  df$d <- rescale01(df$d)\n\n\n\nThree things to making a function: 1. You need to pick a name for the function. Here I’ve used rescale01 because this function rescales a vector to lie between 0 and 1. + Function names should be verbs, and arguments should be nouns. + But if the function can be nouns if they represents known nouns (e.g. mean()) or properties of an object (e.g. coef()) + snake_case vs. camelCase - just be consistent + Avoid common function names as your local will have priority\nYou list the inputs, or arguments, to the function inside function. Here we have just one argument. If we had more the call would look like function(x, y, z).\nDefault value have a value set here. eg. rescale01(tmp, Finite = TRUE)\nThere are rules for some names: ++ x,y,z: vectors ++ df: dataframe ++ i,j: numberic indices (typically rows and columns respectively) ++ n: length, number of rows ++ p: number of columns\nYou place the code you have developed in body of the function, a { block that immediately follows function(…).\nstop() is useful to place in conditions if you only accept certain data; if(finite = FALSE){stop(“you can only have finite number here dude”)}\nreturn() another way to break out of a function and return a value\ninvisible() send an object, but don’t print it. Good for keeping things pipeable\nBetter functions\n\n\n# Reload OG dataframe\ndf <- get_data()\n\n# Make our rescale function even better - add default function argument and stop rule\nrescale01 <- function(x, finite=TRUE) {\n  # check for finite numbers in vector\n  if(finite == FALSE){\n    stop(\"you can only have finite number here dude!\")  \n  } \n  \n  #grab range (rng) to use min (rng[1]) and max (rng[2])\n  rng <- range(x, na.rm = TRUE)\n  (x - rng[1]) / (rng[2] - rng[1])\n  \n}\n\n# Call function with attribute\nrescale01(df$a, finite = TRUE)\n\n\n [1] 0.4496844 0.5073375 0.4230537 1.0000000 0.7514802 0.5768766\n [7] 0.3203819 0.0000000 0.3222939 0.2888145\n\n# Pipe Dream - never break the pipe\nshow_missings <- function(df) {\n  n <- sum(is.na(df))\n  cat(\"Missing values: \", n, \"\\n\", sep = \"\")\n  \n  invisible(df)\n}\n\nshow_missings(mtcars) \n\n\nMissing values: 0\n\nmtcars %>% \n  show_missings() %>% \n  mutate(mpg = ifelse(mpg < 20, NA, mpg)) %>% \n  show_missings() \n\n\nMissing values: 0\nMissing values: 18\n\npurrrFect functions\nFaster as they are written in C\nRun multiple columns within the pipe\n\n\n# What if I want to run all cols with a function?\ndf %>%\nmap(rescale01)\n\n\n\n$a\n [1] 0.4496844 0.5073375 0.4230537 1.0000000 0.7514802 0.5768766\n [7] 0.3203819 0.0000000 0.3222939 0.2888145\n\n$b\n [1] 0.2238090 0.1229223 0.0000000 0.5674141 0.2684266 0.3186047\n [7] 1.0000000 0.5474187 0.5649674 0.1791412\n\n$c\n [1] 1.0000000 0.0000000 0.5075496 0.2040886 0.3651896 0.1734424\n [7] 0.1896919 0.2876244 0.6463605 0.4859685\n\n$d\n [1] 0.09331861 0.36398592 0.32631510 0.14670286 0.48385989 0.70930657\n [7] 1.00000000 0.05151067 0.12948621 0.00000000\n\ndf %>%\n  map_dbl(mean)\n\n\n         a          b          c          d \n 0.6881837  0.1634370 -0.2770932 -0.1907347 \n\n# But what about spitting out a vector instead of a list?\ndf %>%\n  map(rescale01) %>% str()\n\n\nList of 4\n $ a: num [1:10] 0.45 0.507 0.423 1 0.751 ...\n $ b: num [1:10] 0.224 0.123 0 0.567 0.268 ...\n $ c: num [1:10] 1 0 0.508 0.204 0.365 ...\n $ d: num [1:10] 0.0933 0.364 0.3263 0.1467 0.4839 ...\n\ndf %>%\n  modify(rescale01)\n\n\n# A tibble: 10 x 4\n       a     b     c      d\n   <dbl> <dbl> <dbl>  <dbl>\n 1 0.450 0.224 1     0.0933\n 2 0.507 0.123 0     0.364 \n 3 0.423 0     0.508 0.326 \n 4 1     0.567 0.204 0.147 \n 5 0.751 0.268 0.365 0.484 \n 6 0.577 0.319 0.173 0.709 \n 7 0.320 1     0.190 1     \n 8 0     0.547 0.288 0.0515\n 9 0.322 0.565 0.646 0.129 \n10 0.289 0.179 0.486 0     \n\n# What if I want to run a few cols with function?\ndf %>%\n  modify_at(c(\"a\", \"b\"), rescale01)\n\n\n# A tibble: 10 x 4\n       a     b      c      d\n   <dbl> <dbl>  <dbl>  <dbl>\n 1 0.450 0.224  2.18  -0.739\n 2 0.507 0.123 -1.82  -0.113\n 3 0.423 0      0.210 -0.200\n 4 1     0.567 -1.01  -0.616\n 5 0.751 0.268 -0.360  0.164\n 6 0.577 0.319 -1.13   0.685\n 7 0.320 1     -1.06   1.36 \n 8 0     0.547 -0.671 -0.836\n 9 0.322 0.565  0.765 -0.655\n10 0.289 0.179  0.123 -0.955\n\ndf %>%\n  mutate_at(c(\"a\", \"b\"), ~ rescale01(.))\n\n\n# A tibble: 10 x 4\n       a     b      c      d\n   <dbl> <dbl>  <dbl>  <dbl>\n 1 0.450 0.224  2.18  -0.739\n 2 0.507 0.123 -1.82  -0.113\n 3 0.423 0      0.210 -0.200\n 4 1     0.567 -1.01  -0.616\n 5 0.751 0.268 -0.360  0.164\n 6 0.577 0.319 -1.13   0.685\n 7 0.320 1     -1.06   1.36 \n 8 0     0.547 -0.671 -0.836\n 9 0.322 0.565  0.765 -0.655\n10 0.289 0.179  0.123 -0.955\n\ndf2 <- df\n\n\n# What if we're only going to run a function once? Answer: Anonymous functions\ndf %>%\n  modify(function(x) x+2)\n\n\n# A tibble: 10 x 4\n       a     b     c     d\n   <dbl> <dbl> <dbl> <dbl>\n 1  2.64  1.71 4.18   1.26\n 2  2.83  1.42 0.178  1.89\n 3  2.56  1.06 2.21   1.80\n 4  4.43  2.71 0.995  1.38\n 5  3.62  1.84 1.64   2.16\n 6  3.05  1.99 0.872  2.69\n 7  2.22  3.96 0.937  3.36\n 8  1.18  2.65 1.33   1.16\n 9  2.23  2.70 2.77   1.34\n10  2.12  1.58 2.12   1.05\n\n#shortcuts from purrr\ndf %>%\n  modify(~ . + 2)\n\n\n# A tibble: 10 x 4\n       a     b     c     d\n   <dbl> <dbl> <dbl> <dbl>\n 1  2.64  1.71 4.18   1.26\n 2  2.83  1.42 0.178  1.89\n 3  2.56  1.06 2.21   1.80\n 4  4.43  2.71 0.995  1.38\n 5  3.62  1.84 1.64   2.16\n 6  3.05  1.99 0.872  2.69\n 7  2.22  3.96 0.937  3.36\n 8  1.18  2.65 1.33   1.16\n 9  2.23  2.70 2.77   1.34\n10  2.12  1.58 2.12   1.05\n\n# So why are maps powerful with functions. Answer: pipe stuff\ndf %>% \n  mutate(e = c(rep(\"dude\", 5), rep(\"sweet\", 5))) %>%\n  split(.$e) %>%\n  map(~ lm(a ~ b, data =.)) %>%\n  map(summary) %>%\n  map_dbl(\"r.squared\")\n\n\n      dude      sweet \n0.84405175 0.03733455 \n\n\n\n\n",
    "preview": {},
    "last_modified": "2021-11-07T06:28:59-05:00",
    "input_file": {}
  }
]
